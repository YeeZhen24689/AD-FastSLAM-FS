Files : fastSLAM.py, main.py
Note to self on picking up the code again

If the detect_index() robot estimate input is 100% the robot input, the landmarks will be correct 100% of the time. The problem is that that will never be true, there are imperfections in the binomial distribution. 

Currently the two functions to work on is on main.py, line 73 to 76. These are two ways I have tried to solve the problem:

 1) Computing the mean as the robot_estimate_pose this solution fails in the beginning because the particle filter has not fully initialized, but succeeds in every other metric (other than overly close points)

 2) Computing the mean as the most dense part of the probability distribution. This solution works perfectly in the beginning, but as the simulation accumulates more noise, or if the vehicle turns, it seems to fail. (Works on overly close points.)

When picking it back up, brainstorm different ways to clean up the landmark to be as close to the true value as possible. Everything else works, I just wanna take a break from this fast slam this for awhile. 

/\---02 July 2024

Files : fastSLAM.py, main.py
Note to self on picking up the code again

Made a few changes to the core part of the code to utilize both methods of extracting the mean, but this time the mean for the "bins" approach is used to stabilize the simulation before it has a grasp of the track, surprisingly it works 95% of the time. I wonder what else could I do to improve the mean interfacing capabilities of the system?

15 minutes later...

Wait I think I got it. The x and y data can be used to remove extremes in noise fluctuations. Yaw does not seem to have this issue. This might be it. The system is completed and it is somewhat competent in working in the simulation environment.

/\-- 31 July 2024
 